class MicrophoneService {
  constructor() {
    this.mediaRecorder = null;
    this.audioStream = null;
    this.isRecording = false;
    this.audioChunks = [];
    this.audioChunkCount = 0;
    this.totalAudioSize = 0;
    
    console.log('ðŸŽ¤ MicrophoneService: Initialized');
  }

  /**
   * Initialize microphone access
   * @param {Object} constraints - Media constraints
   */
  async initialize(constraints = {}) {
    console.log('ðŸŽ¤ MicrophoneService: Starting initialization...');
    
    const defaultConstraints = {
      audio: {
        sampleRate: 16000,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
      }
    };

    const finalConstraints = { ...defaultConstraints, ...constraints };
    console.log('ðŸŽ¤ MicrophoneService: Using constraints:', finalConstraints);

    try {
      // Check if navigator.mediaDevices is available
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('getUserMedia not supported in this browser');
      }

      console.log('ðŸŽ¤ MicrophoneService: Requesting microphone access...');
      this.audioStream = await navigator.mediaDevices.getUserMedia(finalConstraints);
      
      // Log stream details
      const audioTracks = this.audioStream.getAudioTracks();
      console.log('âœ… MicrophoneService: Microphone access granted');
      console.log('ðŸŽ¤ MicrophoneService: Audio tracks:', audioTracks.length);
      
      if (audioTracks.length > 0) {
        const track = audioTracks[0];
        console.log('ðŸŽ¤ MicrophoneService: Track settings:', track.getSettings());
        console.log('ðŸŽ¤ MicrophoneService: Track capabilities:', track.getCapabilities());
        console.log('ðŸŽ¤ MicrophoneService: Track constraints:', track.getConstraints());
      }
      
      return true;
    } catch (error) {
      console.error('âŒ MicrophoneService: Failed to access microphone:', error);
      console.error('âŒ MicrophoneService: Error details:', {
        name: error.name,
        message: error.message,
        constraint: error.constraint
      });
      throw new Error(`Microphone access denied: ${error.message}`);
    }
  }

  /**
   * Start recording and streaming audio
   * @param {Function} onAudioData - Callback for audio chunks
   * @param {number} chunkSize - Size of audio chunks in ms
   */
  async startRecording(onAudioData, chunkSize = 250) {
    console.log('ðŸŽ¤ MicrophoneService: Starting recording...');
    console.log('ðŸŽ¤ MicrophoneService: Chunk size:', chunkSize, 'ms');

    if (!this.audioStream) {
      console.error('âŒ MicrophoneService: No audio stream available');
      throw new Error('Microphone not initialized. Call initialize() first.');
    }

    if (this.isRecording) {
      console.warn('âš ï¸ MicrophoneService: Already recording');
      return;
    }

    try {
      // Check MediaRecorder support
      if (!window.MediaRecorder) {
        throw new Error('MediaRecorder not supported in this browser');
      }

      // Check supported MIME types
      const supportedTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4',
        'audio/ogg;codecs=opus'
      ];
      
      let selectedMimeType = null;
      for (const type of supportedTypes) {
        if (MediaRecorder.isTypeSupported(type)) {
          selectedMimeType = type;
          break;
        }
      }

      if (!selectedMimeType) {
        console.warn('âš ï¸ MicrophoneService: No supported MIME types found, using default');
        selectedMimeType = 'audio/webm';
      }

      console.log('ðŸŽ¤ MicrophoneService: Using MIME type:', selectedMimeType);

      // Create MediaRecorder for streaming
      this.mediaRecorder = new MediaRecorder(this.audioStream, {
        mimeType: selectedMimeType,
        audioBitsPerSecond: 16000,
      });

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunkCount++;
          this.totalAudioSize += event.data.size;
          
          console.log(`ðŸŽ¤ MicrophoneService: Audio chunk #${this.audioChunkCount} - ${event.data.size} bytes`);
          console.log(`ðŸŽ¤ MicrophoneService: Total audio: ${(this.totalAudioSize / 1024).toFixed(2)} KB`);
          
          // Convert blob to ArrayBuffer for DeepGram
          event.data.arrayBuffer().then(buffer => {
            const uint8Array = new Uint8Array(buffer);
            console.log(`ðŸŽ¤ MicrophoneService: Sending ${uint8Array.length} bytes to callback`);
            onAudioData(uint8Array);
          }).catch(error => {
            console.error('âŒ MicrophoneService: Failed to convert audio data:', error);
          });
        } else {
          console.warn('âš ï¸ MicrophoneService: Received empty audio chunk');
        }
      };

      this.mediaRecorder.onstart = () => {
        console.log('âœ… MicrophoneService: Recording started successfully');
        this.isRecording = true;
        this.audioChunkCount = 0;
        this.totalAudioSize = 0;
      };

      this.mediaRecorder.onstop = () => {
        console.log('ðŸ›‘ MicrophoneService: Recording stopped');
        console.log(`ðŸŽ¤ MicrophoneService: Final stats - ${this.audioChunkCount} chunks, ${(this.totalAudioSize / 1024).toFixed(2)} KB total`);
        this.isRecording = false;
      };

      this.mediaRecorder.onerror = (error) => {
        console.error('âŒ MicrophoneService: MediaRecorder error:', error);
        console.error('âŒ MicrophoneService: Error event details:', {
          type: error.type,
          target: error.target?.state,
          error: error.error
        });
        this.isRecording = false;
      };

      // Log MediaRecorder state before starting
      console.log('ðŸŽ¤ MicrophoneService: MediaRecorder state before start:', this.mediaRecorder.state);

      // Start recording with time slicing
      this.mediaRecorder.start(chunkSize);
      
      console.log('ðŸŽ¤ MicrophoneService: MediaRecorder.start() called');

    } catch (error) {
      console.error('âŒ MicrophoneService: Failed to start recording:', error);
      console.error('âŒ MicrophoneService: Error stack:', error.stack);
      throw error;
    }
  }

  /**
   * Stop recording
   */
  stopRecording() {
    console.log('ðŸŽ¤ MicrophoneService: Attempting to stop recording...');
    
    if (this.mediaRecorder && this.isRecording) {
      console.log('ðŸŽ¤ MicrophoneService: MediaRecorder state before stop:', this.mediaRecorder.state);
      this.mediaRecorder.stop();
      console.log('ðŸŽ¤ MicrophoneService: MediaRecorder.stop() called');
    } else {
      console.log('ðŸŽ¤ MicrophoneService: No active recording to stop');
    }
  }

  /**
   * Cleanup resources
   */
  cleanup() {
    console.log('ðŸŽ¤ MicrophoneService: Starting cleanup...');
    
    this.stopRecording();
    
    if (this.audioStream) {
      const tracks = this.audioStream.getTracks();
      console.log(`ðŸŽ¤ MicrophoneService: Stopping ${tracks.length} audio tracks`);
      
      tracks.forEach((track, index) => {
        console.log(`ðŸŽ¤ MicrophoneService: Stopping track ${index + 1}: ${track.kind} - ${track.label}`);
        track.stop();
      });
      
      this.audioStream = null;
      console.log('âœ… MicrophoneService: Audio stream cleaned up');
    }
    
    this.mediaRecorder = null;
    this.audioChunks = [];
    this.audioChunkCount = 0;
    this.totalAudioSize = 0;
    
    console.log('âœ… MicrophoneService: Cleanup completed');
  }

  /**
   * Get current recording status
   */
  getStatus() {
    const status = {
      isRecording: this.isRecording,
      hasStream: !!this.audioStream,
      hasRecorder: !!this.mediaRecorder,
      audioChunkCount: this.audioChunkCount,
      totalAudioSize: this.totalAudioSize,
      totalAudioSizeKB: (this.totalAudioSize / 1024).toFixed(2),
      recorderState: this.mediaRecorder?.state || 'none',
      streamActive: this.audioStream?.active || false,
      trackCount: this.audioStream?.getTracks()?.length || 0
    };
    
    console.log('ðŸŽ¤ MicrophoneService: Current status:', status);
    return status;
  }

  /**
   * Get audio level for visualization
   */
  getAudioLevel() {
    if (!this.audioStream) {
      console.log('ðŸŽ¤ MicrophoneService: No audio stream for level detection');
      return 0;
    }

    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(this.audioStream);
      
      analyser.smoothingTimeConstant = 0.8;
      analyser.fftSize = 1024;
      
      microphone.connect(analyser);
      
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);
      
      // Calculate average volume
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += dataArray[i];
      }
      
      const level = sum / dataArray.length / 255; // Normalized 0-1
      console.log(`ðŸŽ¤ MicrophoneService: Audio level: ${(level * 100).toFixed(1)}%`);
      
      return level;
    } catch (error) {
      console.error('âŒ MicrophoneService: Failed to get audio level:', error);
      return 0;
    }
  }
}

export default MicrophoneService;
